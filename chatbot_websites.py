# -*- coding: utf-8 -*-
"""Chatbot_websites.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N4ZdY_bka9InK0PXOzlZjxa3XjUTOjg8
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')

# %cd /gdrive/My\ Drive/Chatbot

# %ls

!pip install langchain
!pip install faiss-cpu
!pip install openai
!pip install unstructured
!pip install tiktoken
!pip install InstructorEmbedding
!pip install sentence_transformers
# !pip install nest_asyncio
!pip install gdown

from langchain.document_loaders import UnstructuredURLLoader
from langchain.document_loaders.sitemap import SitemapLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceInstructEmbeddings
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import ChatOpenAI
import faiss
import pickle
import pandas as pd
import json
import os

os.environ['OPENAI_API_KEY'] = 'XXXXXX'

MAX_TEXT_LENGTH=1000  # Maximum num of text characters to use

def auto_truncate(val):

    """Truncate the given text."""

    return val[:MAX_TEXT_LENGTH]

# Load Product data and truncate long text fields

all_prods_df = pd.read_csv("product_data.csv", converters={
    'bullet_point': auto_truncate,
    'item_keywords': auto_truncate,
    'item_name': auto_truncate
})
all_prods_df = pd.read_csv("product_data.csv")
all_prods_df

# Check products that are in US
# all_prods_df['domain_name'].unique()

# all_prods_df_ = all_prods_df[(all_prods_df['country'] == 'US')]
# all_prods_df_.shape

all_prods_df['country'].unique()

all_prods_df['product_type'].unique()

# Replace empty strings with None and drop them along with the NaN values in 'item_name'
all_prods_df['item_keywords'].replace('', None, inplace=True)
all_prods_df.dropna(subset=['item_keywords', 'item_name'], inplace=True)

# Reset pandas dataframe index
all_prods_df.reset_index(drop=True, inplace=True)

# Check if there are any NaN value left in 'item_name'
for i in range(len(all_prods_df['item_name'])):
  try:
    all_prods_df.iloc[i]['item_name'].isdigit()
  except AttributeError as e:
    print(all_prods_df.iloc[i])

{i for i in all_prods_df['product_type'] if i.lower().count('phone') > 0}

# Convert the product dataframe into a dictionary, with key as index and value as metadata for a product
product_metadata = (
    all_prods_df
     .to_dict(orient='index')
)

# Check one of the products
product_metadata[10]

len(product_metadata)

embeddings = HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-xl')
embeddings

texts = [meta['item_name'] for _, meta in product_metadata.items()]
metadatas = list(product_metadata.values())

# Save the embeddings into a vector database
vectorStore_amazon = FAISS.from_texts(texts, embeddings, metadatas)

with open("faiss_store_amazon_fullproducts.pkl", "wb") as f:
    pickle.dump(vectorStore_amazon, f)

with open("faiss_store_amazon_fullproducts.pkl", "rb") as f:
    VectorStore = pickle.load(f)

from langchain.llms import OpenAI
from langchain import OpenAI
from langchain.chains import RetrievalQA # for question and answer retrieval

llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo', cache=False, verbose=True)
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=VectorStore.as_retriever())

llm

query = "What kinds of products do you have?"
result = qa.run(query)
result

query = "I wanna buy shoes, do you have any suggestion?"
result = qa.run(query)
result

query = "I wanna buy men's shoes with US size 9, do you have any suggestion?"
result = qa.run(query)
result

# llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')
# chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=VectorStore.as_retriever())

chain({"question": "What kinds of products do you have?"}, return_only_outputs=True)

chain({"question": "How are you today?"}, return_only_outputs=True)

chain({"question": "What kinds of features do langchain have?"}, return_only_outputs=True)

chain({"question": "How to evaluate a Chatbot?"}, return_only_outputs=True)
